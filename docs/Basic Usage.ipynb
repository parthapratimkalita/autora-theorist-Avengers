{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "# Basic Usage"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What's in this notebook?\n",
    "This notebook demonstrates the basic usage of the ParabolaRegression class. The ParabolaRegression class fits a parabolic function to the data, capturing the quadratic relationship between the independent and dependent variables. This model is useful for identifying non-linear patterns in the data and can be applied to various domains, including economics, psychophysics, and decision-making under uncertainty.\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Import the required libraries.\n",
    "2. Define a benchmark function to evaluate the ParabolaRegression class on synthetic experiments.\n",
    "3. Demonstrate the ParabolaRegression class's performance on three synthetic experiments:\n",
    "4. Steven's Power Law: A psychophysical law describing the relationship between stimulus intensity and perceived magnitude.\n",
    "5. Weber-Fechner Law: A psychophysical law quantifying the minimum change in a stimulus required to be noticeable.\n",
    "6. Expected Utility Model with Two Choice Options: A decision-making model evaluating the expected value of two options under uncertainty.\n",
    "7. Evaluate the ParabolaRegression class's performance on each experiment, including fitting the model, predicting the validation set, and obtaining the identified equation.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Installation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%capture\n",
    "!pip install autora\n",
    "!pip install autora[all-theorists]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Required Libraries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from autora.experiment_runner.synthetic.economics.expected_value_theory import expected_value_theory\n",
    "from autora.experiment_runner.synthetic.psychophysics.stevens_power_law import stevens_power_law\n",
    "from autora.experiment_runner.synthetic.psychophysics.weber_fechner_law import weber_fechner_law\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from autora.theorist.autora_theorist_avengers import ParabolaRegression"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the benchmark function"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def benchmark(experiment_runner, theorist):\n",
    "    # generate all conditions\n",
    "    conditions = experiment_runner.domain()\n",
    "\n",
    "    # generate all corresponding observations\n",
    "    experiment_data = experiment_runner.run(conditions, added_noise=0.01)\n",
    "\n",
    "    # get the name of the independent and independent variables\n",
    "    ivs = [iv.name for iv in experiment_runner.variables.independent_variables]\n",
    "    dvs = [dv.name for dv in experiment_runner.variables.dependent_variables]\n",
    "\n",
    "    # extract the dependent variable (observations) from experiment data\n",
    "    conditions = experiment_data[ivs]\n",
    "    observations = experiment_data[dvs]\n",
    "\n",
    "    # split into train and test datasets\n",
    "    conditions_train, conditions_test, observations_train, observations_test = train_test_split(conditions,\n",
    "                                                                                                observations)\n",
    "\n",
    "    print(\"#### EXPERIMENT CONDITIONS (X):\")\n",
    "    print(conditions)\n",
    "    print(\"#### EXPERIMENT OBSERVATIONS (Y):\")\n",
    "    print(observations)\n",
    "\n",
    "    # fit theorist\n",
    "    theorist.fit(conditions_train, observations_train)\n",
    "\n",
    "    # compute prediction for validation set\n",
    "    predictions = theorist.predict(conditions_test)\n",
    "\n",
    "    # evaluate theorist performance\n",
    "    error = (predictions - observations_test).pow(2)\n",
    "    error = error.mean()\n",
    "\n",
    "    print(\"#### IDENTIFIED EQUATION:\")\n",
    "    print(theorist.print_eqn())\n",
    "\n",
    "    print(\"#### VALIDATION SET MSE:\")\n",
    "    print(error)\n",
    "\n",
    "    experiment_runner.plotter(model=theorist)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Demonstration of the Theorist's fitting, predicting and obtaining capabilities\n",
    "The ParabolaRegression class fits a parabolic function to the data. The parabolic function is defined as:\n",
    "\n",
    "$$\n",
    "y = a \\times x^2 + b \\times x + c\n",
    "$$\n",
    "\n",
    "where $a$, $b$, and $c$ are the coefficients to be estimated. This model captures the quadratic relationship between the independent and dependent variables, allowing for the identification of non-linear patterns in the data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "my_theorist = ParabolaRegression()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Demonstration of the Theorist's recovery of two ground-truth models"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Steven's Power Law\n",
    "\n",
    "Steven's power law describes the relationship between a stimulus's intensity $S$ ($range: [0.01, 5.00]$) and its perceived magnitude $y$. According to this law, humans are less sensitive to changes in high-intensity stimuli compared to low-intensity ones, leading to a power-law relationship between stimulus intensity and perceived magnitude:\n",
    "\n",
    "\n",
    "$\\text{perceived intensity} = {S}^\\alpha$\n",
    "\n",
    "where $\\alpha = 0.80$, resulting in diminishing effects of increases in stimulus intensity."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "benchmark(experiment_runner=stevens_power_law(), theorist=my_theorist)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Weber-Fechner-Law\n",
    "\n",
    "The Weber-Fechner law quantifies the minimum change in a stimulus required to be noticeable. Similar to Steven's power law, the greater the intensity of a stimulus, the larger the change needed to be perceivable. This relationship is hypothesized to be proportional to the logarithm of the ratio between the two stimuli:\n",
    "\n",
    "$\\text{perceived intensity} = \\log\\left(\\dfrac{S_1}{S_2}\\right)$\n",
    "\n",
    "\n",
    "where $S_1$ ($range: [0.01, 5.00]$) is the intensity of a physical stimulus (e.g., the luminosity of a lamp), $S_2$ ($range: [0.01, 5.00]$ ) is a reference stimulus (e.g., the luminosity of a background light), and $y$ is the perceived stimulus intensity (e.g. the perception of the lamp's luminosity)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "benchmark(experiment_runner=weber_fechner_law(), theorist=my_theorist)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Expected Utility Model with Two Choice Options\n",
    "\n",
    "The expected utility model evaluates decision-making under uncertainty, quantifying the expected value of different choices based on their potential outcomes and associated probabilities. The model assumes that individuals aim to maximize their expected utility when faced with two options. Each option has a specific value and probability, influenced by a certain level of noise.\n",
    "\n",
    "For two choice options, the expected value of each option is calculated as follows:\n",
    "\n",
    "$$\n",
    "E_A = V_A \\times P_A\n",
    "$$\n",
    "\n",
    "$$\n",
    "E_B = V_B \\times P_B\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $V_A$ and $V_B$ represent the values of options A and B respectively.\n",
    "- $P_A$ and $P_B$ represent the probabilities associated with these options.\n",
    "\n",
    "The probability of choosing option A $P_{\\text{choose}_A}$ is then determined using the softmax function, which considers the expected values of both options and a choice temperature parameter that influences the sensitivity to differences in expected values:\n",
    "\n",
    "$$\n",
    "P_{\\text{choose}_A} = \\frac{\\exp(E_A / \\beta)}{\\exp(E_A / \\beta) + \\exp(E_B / \\beta)}\n",
    "$$\n",
    "\n",
    "In this model:\n",
    "- $\\beta$ controls the degree of randomness in the choice, with higher values leading to more exploration and lower values leading to more deterministic choices based on the expected values.\n",
    "- The softmax function ensures that the probabilities sum to 1, providing a normalized measure of the likelihood of choosing each option.\n",
    "\n",
    "This model captures the influence of value, probability, and noise on decision-making, reflecting the complexity and variability of human choices under uncertainty."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "benchmark(experiment_runner=expected_value_theory(), theorist=my_theorist)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
